{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': True, 'cat': True, 'is': True, 'very': True, 'cute': True}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def format_sentence(sent):\n",
    "    return({word: True for word in nltk.word_tokenize(sent)})\n",
    "\n",
    "print(format_sentence(\"The cat is very cute\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 7226 instances, test on 1808 instances\n"
     ]
    }
   ],
   "source": [
    "pos = []\n",
    "with open(\"./data/pos_reviews.txt\") as f:\n",
    "    for i in f:\n",
    "        pos.append([format_sentence(i), 'pos'])\n",
    "        \n",
    "neg = []\n",
    "with open(\"./data/neg_reviews.txt\") as f:\n",
    "    for i in f:\n",
    "        neg.append([format_sentence(i), 'neg'])\n",
    "        \n",
    "training_set_size = .8\n",
    "pos_training_cutoff = int((training_set_size)*len(pos))\n",
    "neg_training_cutoff = int((training_set_size)*len(neg))\n",
    "        \n",
    "training_set = pos[:pos_training_cutoff] + neg[:neg_training_cutoff]\n",
    "test_set = pos[pos_training_cutoff:] + neg[neg_training_cutoff:]\n",
    "print('train on %d instances, test on %d instances' % (len(training_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                Superman = True              neg : pos    =     46.5 : 1.0\n",
      "                   AVOID = True              neg : pos    =     40.3 : 1.0\n",
      "            unacceptable = True              neg : pos    =     40.3 : 1.0\n",
      "                   Titus = True              neg : pos    =     34.1 : 1.0\n",
      "              IMPOSSIBLE = True              neg : pos    =     34.1 : 1.0\n",
      "                     WTF = True              neg : pos    =     34.1 : 1.0\n",
      "                   WORST = True              neg : pos    =     31.6 : 1.0\n",
      "                   Regis = True              neg : pos    =     27.9 : 1.0\n",
      "                tag-team = True              neg : pos    =     27.9 : 1.0\n",
      "             uninstalled = True              neg : pos    =     27.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training_set)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "testPos = \"Dogs are awesome!\"\n",
    "testNeg = \"This game is trash\"\n",
    "testDoubleNeg = \"not bad\"\n",
    "\n",
    "print(classifier.classify(format_sentence(testPos)))\n",
    "print(classifier.classify(format_sentence(testNeg)))\n",
    "print(classifier.classify(format_sentence(testDoubleNeg)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive precision: 0.984304932735426\n",
      "Positive recall: 0.5379901960784313\n",
      "Positive F-Measure: 0.6957210776545166\n",
      "Negative precision: 0.17685589519650655\n",
      "Negative recall: 0.9204545454545454\n",
      "Negative F-Measure: 0.2967032967032967\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from nltk.metrics.scores import (precision, recall, f_measure)\n",
    "\n",
    "ref_sets = collections.defaultdict(set)\n",
    "test_sets = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    ref_sets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    test_sets[observed].add(i)\n",
    "    \n",
    "print('Positive precision: ' + str(precision(ref_sets['pos'], test_sets['pos'])))\n",
    "print('Positive recall: ' + str(recall(ref_sets['pos'], test_sets['pos'])))\n",
    "print('Positive F-Measure: ' + str(f_measure(ref_sets['pos'], test_sets['pos'])))\n",
    "\n",
    "print('Negative precision: ' + str(precision(ref_sets['neg'], test_sets['neg'])))\n",
    "print('Negative recall: ' + str(recall(ref_sets['neg'], test_sets['neg'])))\n",
    "print('Negative F-Measure: ' + str(f_measure(ref_sets['neg'], test_sets['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 5420 instances, test on 3614 instances\n"
     ]
    }
   ],
   "source": [
    "# Training on a medium-sized set\n",
    "        \n",
    "training_set_size2 = .6\n",
    "pos_training_cutoff2 = int((training_set_size2)*len(pos))\n",
    "neg_training_cutoff2 = int((training_set_size2)*len(neg))\n",
    "        \n",
    "training_set2 = pos[:pos_training_cutoff2] + neg[:neg_training_cutoff2]\n",
    "test_set2 = pos[pos_training_cutoff2:] + neg[neg_training_cutoff2:]\n",
    "print('train on %d instances, test on %d instances' % (len(training_set2), len(test_set2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier2 = NaiveBayesClassifier.train(training_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive precision: 0.9816922315685305\n",
      "Positive recall: 0.6080294207784248\n",
      "Positive F-Measure: 0.7509462528387586\n",
      "Negative precision: 0.19711236660389203\n",
      "Negative recall: 0.8945868945868946\n",
      "Negative F-Measure: 0.3230452674897119\n"
     ]
    }
   ],
   "source": [
    "ref_sets2 = collections.defaultdict(set)\n",
    "test_sets2 = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set2):\n",
    "    ref_sets2[label].add(i)\n",
    "    observed2 = classifier2.classify(feats)\n",
    "    test_sets2[observed2].add(i)\n",
    "    \n",
    "print('Positive precision: ' + str(precision(ref_sets2['pos'], test_sets2['pos'])))\n",
    "print('Positive recall: ' + str(recall(ref_sets2['pos'], test_sets2['pos'])))\n",
    "print('Positive F-Measure: ' + str(f_measure(ref_sets2['pos'], test_sets2['pos'])))\n",
    "\n",
    "print('Negative precision: ' + str(precision(ref_sets2['neg'], test_sets2['neg'])))\n",
    "print('Negative recall: ' + str(recall(ref_sets2['neg'], test_sets2['neg'])))\n",
    "print('Negative F-Measure: ' + str(f_measure(ref_sets2['neg'], test_sets2['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 3612 instances, test on 5422 instances\n"
     ]
    }
   ],
   "source": [
    "# Training on a small set\n",
    "        \n",
    "training_set_size3 = .4\n",
    "pos_training_cutoff3 = int((training_set_size3)*len(pos))\n",
    "neg_training_cutoff3 = int((training_set_size3)*len(neg))\n",
    "        \n",
    "training_set3 = pos[:pos_training_cutoff3] + neg[:neg_training_cutoff3]\n",
    "test_set3 = pos[pos_training_cutoff3:] + neg[neg_training_cutoff3:]\n",
    "print('train on %d instances, test on %d instances' % (len(training_set3), len(test_set3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier3 = NaiveBayesClassifier.train(training_set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive precision: 0.9877149877149877\n",
      "Positive recall: 0.41062308478038817\n",
      "Positive F-Measure: 0.5800865800865801\n",
      "Negative precision: 0.14821375848833776\n",
      "Negative recall: 0.952561669829222\n",
      "Negative F-Measure: 0.2565150740929995\n"
     ]
    }
   ],
   "source": [
    "ref_sets3 = collections.defaultdict(set)\n",
    "test_sets3 = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set3):\n",
    "    ref_sets3[label].add(i)\n",
    "    observed3 = classifier3.classify(feats)\n",
    "    test_sets3[observed3].add(i)\n",
    "    \n",
    "print('Positive precision: ' + str(precision(ref_sets3['pos'], test_sets3['pos'])))\n",
    "print('Positive recall: ' + str(recall(ref_sets3['pos'], test_sets3['pos'])))\n",
    "print('Positive F-Measure: ' + str(f_measure(ref_sets3['pos'], test_sets3['pos'])))\n",
    "\n",
    "print('Negative precision: ' + str(precision(ref_sets3['neg'], test_sets3['neg'])))\n",
    "print('Negative recall: ' + str(recall(ref_sets3['neg'], test_sets3['neg'])))\n",
    "print('Negative F-Measure: ' + str(f_measure(ref_sets3['neg'], test_sets3['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 8130 instances, test on 904 instances\n"
     ]
    }
   ],
   "source": [
    "# Training on a very large set\n",
    "        \n",
    "training_set_size4 = .9\n",
    "pos_training_cutoff4 = int((training_set_size4)*len(pos))\n",
    "neg_training_cutoff4 = int((training_set_size4)*len(neg))\n",
    "        \n",
    "training_set4 = pos[:pos_training_cutoff4] + neg[:neg_training_cutoff4]\n",
    "test_set4 = pos[pos_training_cutoff4:] + neg[neg_training_cutoff4:]\n",
    "print('train on %d instances, test on %d instances' % (len(training_set4), len(test_set4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier4 = NaiveBayesClassifier.train(training_set4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive precision: 0.9879227053140096\n",
      "Positive recall: 0.5012254901960784\n",
      "Positive F-Measure: 0.6650406504065041\n",
      "Negative precision: 0.020076764098021848\n",
      "Negative recall: 0.9431818181818182\n",
      "Negative F-Measure: 0.28719723183391005\n"
     ]
    }
   ],
   "source": [
    "ref_sets4 = collections.defaultdict(set)\n",
    "test_sets4 = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set4):\n",
    "    ref_sets4[label].add(i)\n",
    "    observed4 = classifier4.classify(feats)\n",
    "    test_sets4[observed4].add(i)\n",
    "    \n",
    "print('Positive precision: ' + str(precision(ref_sets4['pos'], test_sets4['pos'])))\n",
    "print('Positive recall: ' + str(recall(ref_sets4['pos'], test_sets4['pos'])))\n",
    "print('Positive F-Measure: ' + str(f_measure(ref_sets4['pos'], test_sets4['pos'])))\n",
    "\n",
    "print('Negative precision: ' + str(precision(ref_sets4['neg'], test_sets3['neg'])))\n",
    "print('Negative recall: ' + str(recall(ref_sets4['neg'], test_sets4['neg'])))\n",
    "print('Negative F-Measure: ' + str(f_measure(ref_sets4['neg'], test_sets4['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
